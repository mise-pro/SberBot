Изначальная постановка:

Задание:
Предоставлены 40к пар вопрос-ответ из обсуждения вконтакте, https://vk.com/topic-22522055_25921627. По ним нужно:
- Кластеризовать по темам обращений. Темы должны быть узкие, внутри которых по смыслу не должно быть подкатегорий
- Каждому кластеру проставить автоматически название, о чём сообщения внутри него
- Сделать автоответчик на вопросы. Формат ответа: [список 5 ближайших троек вида: {вопрос, ответ, confidence}, а также список названий/эталонных вопросов 5 ближайших кластеров с некоторым confidence]
- Оформить в виде бота без всяких кнопок, просто текстовый вопрос - текстовый ответ.

Модификация задания:
- без бота
- сформировать опыт работы с библиотеками по анализу текстов

Как работает:
Есть 2 ноутбука – основной (usingLDAviaScipy) и вспомогательный (LDAbestModelSearch). Есть несколько файлов, в которых разные функции (хранить это всё в jupyter – ад).

Вспомогательный служит для анализа модели: подбора словаря, разряженности модели, визуализации всего этого, подбора gridSearch. Полученная модель сохраняется в файле.

В основном ноутбуке реализованы 2 режима работы: один расчитывает производные от модели с нуля, второй – когда все загружается из сохраненных дампов (работает на порядки быстрее).

Есть еще переключатель дебаг, когда выводится больше всякой информации.

Алгоритм такой: 
- грузим/вычисляем модель;
- вводим новый вопрос и обрабатываем его;
- пытаемся найти близкие вопросы средствами модели (по темам) внутри кластера или без кластера, также пробуем найти близкий вопрос средствами косинусного расстояния
- выводим это вместе с ответами и вероятностями

Для работы надо скачать все и архив с начальными данными распаковать.
Python 3

Что не было сделано:
- не проведена тщательная лемматизация для русского языка (попытки прикрутить адекватный словарь лем не увенчалась успехом). Это является основным стопером для хорошего качества модели, но требует копания именно в работу с текстом, что на тот момент было не очень инетересно; по этой же причине нет возможности точно определить, сколько кластеров оптимально. Остановился на 10, но моделирование говорит, что чем меньше – тем лучше.
- не удалось перевести это задание в pyCharm, посколько там начались проблемы с multiprocessing, а отладка этого не была задачей. Поэтому ограничился 2мя ноутбуками на jupyter.
- опробованы, но не полностью реализованы принципы PEP8
- опробованы алгоритмы kMeans (после пробы отказался)

Важные материалы:
- https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/
- https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21
- http://mathling.phil.spbu.ru/node/160

